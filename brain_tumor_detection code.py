# -*- coding: utf-8 -*-
"""Brain Tumor Detection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1KfLVsD7ABHS3dxWbxML8zzxlPcH4SHt-
"""

import warnings
warnings.filterwarnings('ignore')
import numpy as np
import matplotlib.pyplot as plt
import os
import math
import shutil
import glob

# unzip the downloaded dataset

unzip /content/Own-Dataset.zip

# count the number of images in the respective classes
# 1- Tumor
# 2- No Tumor (Normal)

# first creating the directory
ROOT_DIR = "/content/Own-Dataset"
number_of_images = {}

for dir in os.listdir(ROOT_DIR):
  number_of_images[dir] = len(os.listdir(os.path.join(ROOT_DIR,dir)))

#counting number of images
number_of_images.items()

len(os.listdir("/content/Own-Dataset"))

"""We will split the data such that
1.   80% for Train data
2.   10% for validation
3.   10% for testing




"""

# we will create the train, validation, testing datasets folder using function

def dataFolder(folderName, split):
  if not os.path.exists("./" +folderName):
    os.mkdir("./" +folderName)

    for dir in os.listdir(ROOT_DIR):
      os.makedirs("./" +folderName+"/" + dir)
      for img in np.random.choice(a=os.listdir(os.path.join(ROOT_DIR, dir)), size = (math.floor(split*number_of_images[dir])-5), replace=False):
        O = os.path.join(ROOT_DIR, dir, img)
        D = os.path.join("./" +folderName, dir)
        shutil.copy(O,D)
        os.remove(O)
  else:
    print(f"{folderName} folder already exist")

dataFolder("train", 0.8)

dataFolder("validation", 0.1)

dataFolder("test", 0.1)

# this code will shows that how many images are left after train, validation, test

number_of_images = {}

for dir in os.listdir(ROOT_DIR):
  number_of_images[dir] = len(os.listdir(os.path.join(ROOT_DIR,dir)))

number_of_images.items()

import os
import cv2
import matplotlib.pyplot as plt
import random

def plot_images(dataset_path, categories, num_images_per_category=5):
    """
    Plot a specified number of images for each category (e.g., Normal, Tumor), ensuring 5 columns per row.

    Parameters:
        dataset_path (str): Path to the dataset directory.
        categories (list): List of category folder names (e.g., ['Normal', 'Tumor']).
        num_images_per_category (int): Number of images to display per category.
    """
    columns = 5
    rows = 5  # Total of 25 images
    total_images = rows * columns
    num_categories = len(categories)

    # Adjust the number of images per category if the total doesn't add up to 25
    images_per_category = total_images // num_categories
    if total_images % num_categories != 0:
        images_per_category += 1

    plt.figure(figsize=(15, rows * 3))

    for category_index, category in enumerate(categories):
        category_path = os.path.join(dataset_path, category)
        images = os.listdir(category_path)

        # Randomly select images to display
        selected_images = random.sample(images, min(images_per_category, len(images)))

        for i, img_name in enumerate(selected_images):
            img_path = os.path.join(category_path, img_name)
            img = cv2.imread(img_path)
            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert to RGB

            # Plot the image
            plt.subplot(rows, columns, category_index * columns + i + 1)
            plt.imshow(img)
            plt.axis('off')
            plt.title(f"{category}")

    plt.tight_layout()
    plt.show()

# Specify dataset path and categories
dataset_path = "/content/train"  # Replace with the path to your dataset
categories = ["Normal", "Tumor"]

# Plot images
plot_images(dataset_path, categories, num_images_per_category=5)

import os
import cv2
import matplotlib.pyplot as plt
import random

def plot_images(dataset_path, categories, num_images_per_category=5):
    """
    Plot a specified number of images for each category (e.g., Normal, Tumor), ensuring 5 columns per row.

    Parameters:
        dataset_path (str): Path to the dataset directory.
        categories (list): List of category folder names (e.g., ['Normal', 'Tumor']).
        num_images_per_category (int): Number of images to display per category.
    """
    columns = 5
    rows = 5  # Total of 25 images
    total_images = rows * columns
    num_categories = len(categories)

    # Adjust the number of images per category if the total doesn't add up to 25
    images_per_category = total_images // num_categories
    if total_images % num_categories != 0:
        images_per_category += 1

    plt.figure(figsize=(15, rows * 3))

    for category_index, category in enumerate(categories):
        category_path = os.path.join(dataset_path, category)
        images = os.listdir(category_path)

        # Randomly select images to display
        selected_images = random.sample(images, min(images_per_category, len(images)))

        for i, img_name in enumerate(selected_images):
            img_path = os.path.join(category_path, img_name)
            img = cv2.imread(img_path)
            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert to RGB

            # Plot the image
            plt.subplot(rows, columns, category_index * columns + i + 1)
            plt.imshow(img)
            plt.axis('off')
            plt.title(f"{category}")

    plt.tight_layout()
    plt.show()

# Specify dataset path and categories
dataset_path = "/content/test"  # Replace with the path to your dataset
categories = ["Normal", "Tumor"]

# Plot images
plot_images(dataset_path, categories, num_images_per_category=5)

import os
import cv2
import matplotlib.pyplot as plt
import random

def plot_images(dataset_path, categories, num_images_per_category=5):
    """
    Plot a specified number of images for each category (e.g., Normal, Tumor), ensuring 5 columns per row.

    Parameters:
        dataset_path (str): Path to the dataset directory.
        categories (list): List of category folder names (e.g., ['Normal', 'Tumor']).
        num_images_per_category (int): Number of images to display per category.
    """
    columns = 5
    rows = 5  # Total of 25 images
    total_images = rows * columns
    num_categories = len(categories)

    # Adjust the number of images per category if the total doesn't add up to 25
    images_per_category = total_images // num_categories
    if total_images % num_categories != 0:
        images_per_category += 1

    plt.figure(figsize=(15, rows * 3))

    for category_index, category in enumerate(categories):
        category_path = os.path.join(dataset_path, category)
        images = os.listdir(category_path)

        # Randomly select images to display
        selected_images = random.sample(images, min(images_per_category, len(images)))

        for i, img_name in enumerate(selected_images):
            img_path = os.path.join(category_path, img_name)
            img = cv2.imread(img_path)
            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert to RGB

            # Plot the image
            plt.subplot(rows, columns, category_index * columns + i + 1)
            plt.imshow(img)
            plt.axis('off')
            plt.title(f"{category}")

    plt.tight_layout()
    plt.show()

# Specify dataset path and categories
dataset_path = "/content/validation"  # Replace with the path to your dataset
categories = ["Normal", "Tumor"]

# Plot images
plot_images(dataset_path, categories, num_images_per_category=5)

"""**Model Building**"""




#### Install the library before proceeding further in the code
#### pip install tensorflow


from tensorflow.keras.layers import Conv2D, MaxPool2D, Dropout, Flatten, Dense, BatchNormalization, GlobalAveragePooling2D
from tensorflow.keras.models import Sequential
from tensorflow.keras.preprocessing.image import ImageDataGenerator

# CNN Model

model = Sequential()

#different layers of data filtering

#layers apply convolutional filters to extract features from the input data.

# first convolutional layer and input layer
model.add(Conv2D(filters = 16, kernel_size = (3, 3), activation = 'relu', input_shape = (224,224,3)))

# second convolutional layer
model.add(Conv2D(filters = 36, kernel_size = (3, 3), activation = 'relu'))

# First Max Pooling Layer
model.add(MaxPool2D(pool_size=(2,2)))

#third convolutional layer
model.add(Conv2D(filters = 64, kernel_size = (3, 3), activation = 'relu'))

# second max pooling layer
model.add(MaxPool2D(pool_size=(2,2)))

# fourth convolutional layer
model.add(Conv2D(filters = 128, kernel_size = (3, 3), activation = 'relu'))

# third max pooling layer
model.add(MaxPool2D(pool_size=(2,2)))

# dropout layer to prevent overfitting
model.add(Dropout(rate = 0.25))

#Converts the 3D feature maps (from convolutional layers) into a 1D vector so they can be passed to fully connected layers.
model.add(Flatten())

#These layers combine the features extracted by the convolutional layers to make predictions.
model.add(Dense(units=64, activation='relu'))

model.add(Dropout(rate = 0.25))

#These layers combine the features extracted by the convolutional layers to make predictions.
model.add(Dense(units=1, activation='sigmoid'))

#overview of the model, including details about the layers, their output shapes, the number of parameters, and the total number of trainable parameters in the model
model.summary()

import keras

model.compile(optimizer = 'adam', loss = keras.losses.binary_crossentropy, metrics = ['accuracy'])

"""Preparing our data using Data Generator"""

# training data
def preprocessingImages1(path):
  """
  input : Path
  output : Pre processed images
  """

  # data augmentation and preprocessing
  image_data = ImageDataGenerator(zoom_range=0.2,
                                  shear_range=0.2,
                                  rescale = 1/255,
                                  horizontal_flip=True)   #data augmentation


  image = image_data.flow_from_directory(directory = path, target_size=(224,224), batch_size=32, class_mode = 'binary')

  return image

path = "/content/train"
train_data = preprocessingImages1(path)

train_data.class_indices

#testing data
def preprocessingImages2(path):
  """
  input : Path
  output : Pre processed images
  """
  image_data = ImageDataGenerator(rescale = 1/255)
  image = image_data.flow_from_directory(directory = path, target_size=(224,224), batch_size=32, class_mode = 'binary')

  return image

path = "/content/test"
test_data = preprocessingImages2(path)

path = "/content/validation"
validate_data = preprocessingImages2(path)

#Early stopping and model check point

from keras.callbacks import ModelCheckpoint, EarlyStopping

# early stopping
es = EarlyStopping(monitor = "val_accuracy", min_delta = 0.01, patience=10, verbose=1, mode='auto')

# model checkpoint
mc = ModelCheckpoint(monitor = "val_accuracy", filepath="./bestmodel.keras", verbose = 1, save_best_only = True, mode = 'auto')

cd = [es,mc]

"""**Model Training**"""

hs = model.fit(train_data,
                         steps_per_epoch=30,
                         epochs=30,
                         verbose=1,
                         validation_data = validate_data,
                         validation_steps = 16,
                         callbacks = cd)

# load the best model that you trained
from tensorflow.keras.models import load_model
model = load_model("/content/bestmodel.keras")

# check the accuracy of model
acc = model.evaluate(test_data)[1]
print(f"The accuracy of model is {acc*100} %")

"""**Training the model with the help of pretrained model to increase the accuracy. This will only work if we already train the above model and the retrain using the the following steps**"""

import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras.layers import Flatten, Dense
from tensorflow.keras.models import Model, load_model
from tensorflow.keras.applications import MobileNet


base_model = MobileNet(input_shape=(224,224,3), include_top = False)

for layer in base_model.layers:
  layer.trainable= False

X = Flatten()(base_model.output)
X = Dense(units=1, activation = 'sigmoid')(X)


model = Model(base_model.input, X)

model.summary()

model.compile(optimizer = 'rmsprop', loss = keras.losses.binary_crossentropy, metrics=['accuracy'])

## Call back


from keras.callbacks import ModelCheckpoint, EarlyStopping

## model checkpoint
mc = ModelCheckpoint(filepath = '/content/bestmodel.keras', monitor = 'val_accuracy', verbose = 1, save_best_only= True)

## Early Stopping
es = EarlyStopping(monitor="val_accuracy", restore_best_weights=True, min_delta = 0.01, patience= 10, verbose =1)

cb = [mc,es]

hist = model.fit(train_data,
                           steps_per_epoch=30,
                           epochs=15,
                           validation_data= validate_data,
                           validation_steps= 16,
                           callbacks = cb)
                    ## patience = 10 , verbose = 1

# load the best model that you trained
model = load_model("/content/bestmodel.keras")

# check the accuracy of model
acc = model.evaluate(test_data)[1]
print(f"our model's accuracy is {acc*100} %")

"""**Below part common in both mdoel**"""

# Model Graphical Interpretation

h = hist.history
h.keys()

import matplotlib.pyplot as plt
import numpy as np

# Extract data from the history object
epochs = np.arange(1, len(hist.history['loss']) + 1)
train_loss = hist.history['loss']
val_loss = hist.history['val_loss']
train_acc = hist.history['accuracy']
val_acc = hist.history['val_accuracy']

# Define number of rows and columns in the grid
rows = 2
cols = 2

# Create a figure and set of subplots
fig, axes = plt.subplots(rows, cols, figsize=(12, 8))

# Plot on each subplot with different parameters
# Plot 1: Train loss vs Epochs
axes[0, 0].plot(epochs, train_loss, label='Train Loss', color='blue')
axes[0, 0].set_title('Train Loss')
axes[0, 0].set_xlabel('Epochs')
axes[0, 0].set_ylabel('Loss')
axes[0, 0].legend()

# Plot 2: Validation loss vs Epochs
axes[0, 1].plot(epochs, val_loss, label='Validation Loss', color='red')
axes[0, 1].set_title('Validation Loss')
axes[0, 1].set_xlabel('Epochs')
axes[0, 1].set_ylabel('Loss')
axes[0, 1].legend()

# Plot 3: Train accuracy vs Epochs
axes[1, 0].plot(epochs, train_acc, label='Train Accuracy', color='green')
axes[1, 0].set_title('Train Accuracy')
axes[1, 0].set_xlabel('Epochs')
axes[1, 0].set_ylabel('Accuracy')
axes[1, 0].legend()

# Plot 4: Validation accuracy vs Epochs
axes[1, 1].plot(epochs, val_acc, label='Validation Accuracy', color='orange')
axes[1, 1].set_title('Validation Accuracy')
axes[1, 1].set_xlabel('Epochs')
axes[1, 1].set_ylabel('Accuracy')
axes[1, 1].legend()

# Adjust layout to prevent overlap
plt.tight_layout()

# Show the plots
plt.show()

import matplotlib.pyplot as plt

plt.plot(h['accuracy'], c="red")
plt.plot(h['val_accuracy'], c="blue")

plt.title("accuracy vs val_accuracy")
plt.show()

import matplotlib.pyplot as plt

plt.plot(h['loss'], c="red")
plt.plot(h['val_loss'])

plt.title("loss vs val_loss")
plt.show()

"""**To know the class of tumor is 0 or 1**"""

train_data.class_indices

"""**Result prediction of our model**"""

from keras.preprocessing.image import load_img, img_to_array

# load and preprocess the image
path = "/content/validation/Tumor/G_107_VF_.jpg"
img = load_img(path, target_size = (224,224)) #resize to match model input size

input_arr = img_to_array(img)/ 255.0 # Normalize pixel value to [0,1]


# Display the image
plt.imshow(input_arr)

#plt.axis('off')   #hide axis for better visualisation
plt.show()

input_arr.shape # Input shape (before adding batch dimesnsion)

# Expand dimensions to match the batch input format
input_arr = np.expand_dims(input_arr, axis = 0)

# Make the prediction
pred = (model.predict(input_arr) > 0.5)[0][0]
# pred = np.argmax(model.predict(input_arr), axis=1)[0]
pred


if pred == 0:
  print("The MRI is not having brain tumor or Normal MRI")
else:
  print("The MRI is having brain tumor or Tumor MRI")



#### Install the library before proceeding further in the code
#### pip install torchviz

import torch
import torch.nn as nn
from torchviz import make_dot

# Assuming SelfONN2dLayer is defined
class SelfONN2dLayer(nn.Module):
    def __init__(self, in_channels, out_channels, kernel_size, q):
        super(SelfONN2dLayer, self).__init__()
        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, padding=1)
    def forward(self, x):
        return self.conv(x)

# Model definition
class TumorONNModel(nn.Module):
    def __init__(self):
        super(TumorONNModel, self).__init__()
        self.model = nn.Sequential(
            nn.Tanh(),
            SelfONN2dLayer(3, 16, kernel_size=3, q=3),
            nn.MaxPool2d(2, 2),
            SelfONN2dLayer(16, 32, kernel_size=3, q=3),
            nn.MaxPool2d(2, 2),
            nn.Flatten(),
            nn.Linear(32 * 14 * 14, 128),
            nn.ReLU(),
            nn.Linear(128, 1),
            nn.Sigmoid()
        )

    def forward(self, x):
        return self.model(x)

# Create the model and dummy input
model = TumorONNModel()
dummy_input = torch.randn(1, 3, 56, 56)  # Example input size
output = model(dummy_input)

# Visualize the computational graph
dot = make_dot(output, params=dict(model.named_parameters()))
dot.render('tumor_onn_model', format='svg', cleanup=True)

from IPython.display import SVG, display

# Load and display the SVG file
display(SVG('tumor_onn_model.svg'))